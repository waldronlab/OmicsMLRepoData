---
title: "Harmonize age information in cbio data"
author:
  - Sehyun Oh
  - Kai Gravel-Pucillo
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
    html:
        fontsize: 14pxs
        toc: true
        top-depth: 3
abstract: "Prepare U24 Supplement: AI/ML-ready"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                    warning = FALSE,
                    message = FALSE,
                    collapse = TRUE,
                    eval = TRUE)
```

# Overview

This .qmd file demonstrates a workflow for curating and harmonizing 
age data with the cbioportal dataset.
This file curates information from 6 original columns to produce a curated 
column relating to the age of the patient.


# Setup

## Load Packages

```{r load}
suppressPackageStartupMessages({
  library(curatedMetagenomicData)
  library(tidyverse)
  library(googlesheets4)
  library(rols)
  library(dplyr)
  library(hash)
  library(vctrs)
  library(rvest)
})
```

## Setup for Curation

We will first add a `curation_id` consisting of study ID and patient ID (`studyId:patientId`) to avoid confusion due to duplicated samples.
```{r curation_setup}
# Load cbio data
cbio <- readRDS("C:\\Users\\Owner\\Desktop\\CUNY Internship\\cBioPortal_all_clinicalData_combined_2023-05-18.rds")

# Add curation ID
cbio$curation_id <- paste(cbio$studyId, cbio$patientId, cbio$sampleId, sep = ":")

# Setup google sheets link to mapping table
url <- "https://docs.google.com/spreadsheets/d/1HDB845dzSFu25i6xEPfk06eR9n70IB-2uGsV4ZWpnVM/edit#gid=0"

ss <- googledrive::as_id(url)

# Define a project directory
proj_dir <- "C:\\Users\\Owner\\Desktop\\CUNY Internship\\cbio\\Age\\"
```


# Exploratory Data Analysis & Data Curation

## Identifying Relevant Columns & Completeness

Next, we will identify the columns containing values relating to the Age of 
the patient.
Due to the large number of feature columns which contain a number of both broad
and very specific column types, we will first query column names for relevant 
terms and compile these results into a map of original columns and their
potential curated columns.
```{r}
# Create a list of potentially relevant columns based on search terms
age_columns <- select(cbio, contains("age")) %>% select(-contains(c("coverage", "stage", "percentage", "agent", "dosage", "lineage", "miscarriage", "esophageal", "macrophage", "salvage", "heritage")))

potential_columns <- data.frame(colnames(age_columns))

# Iterate through these columns to create a dataframe of each column's unique values and completeness
for (col in 1:length(age_columns)){
  potential_columns$unique_vals[col] <- paste(unlist(unique(age_columns[,col]), use.names = F), collapse=" ")
  potential_columns$completeness[col] <- (nrow(age_columns) - length(which(is.na(age_columns[,col]))))/nrow(age_columns)
}

# Remove rows where unique_vals is NA
potential_columns <- filter(potential_columns, unique_vals!="NA")

# Sort by completeness
potential_columns <- arrange(potential_columns, desc(completeness))

# Export to csv file to manually remove irrelevant columns
write.csv(potential_columns, 
          file = file.path(proj_dir, "potential_age_columns_map.csv"),
          row.names = FALSE)
```

After manually removing and rearranging some columns which are irrelevant to 
this particular curation we can then create a tibble dataframe and import the 
map of columns to include in this curation:
```{r}
# Create tibble
cbio <- tibble(cbio)

# Change "Diagnosis Age" column name
cbio <- cbio %>% rename("DIAGNOSIS.AGE" = "DIAGNOSIS AGE")

# Load Potential columns map csv file
pot_col_map <- read.csv(file=file.path(proj_dir, "potential_age_columns_map.csv"))

# Create a subset of cbio containing only relevant columns
age_cols_cbio <- cbio[,c("curation_id", pot_col_map$colnames.age_columns.[which(pot_col_map$curated_col!="other")])]
```

Then we will evaluate the completeness and unique values of each of the relevant
columns, and export this dataframe to manually group columns into a smaller set
of curated columns:
```{r}
# Create a summary dataframe of the relevant columns
summary_age_cols <- data.frame(colnames(age_cols_cbio[,2:ncol(age_cols_cbio)]))

# Iterate through these columns to create a summary of each column's completeness
for (col in 1:nrow(summary_age_cols)){
  summary_age_cols$completeness[col] <- (nrow(age_cols_cbio) - length(which(is.na(age_cols_cbio[,col+1]))))/nrow(age_cols_cbio)
  summary_age_cols$num_na_vals[col] <- length(which(is.na(age_cols_cbio[,col+1])))
  summary_age_cols$unique[col] <- paste(unlist(unique(age_cols_cbio[,col+1]), use.names=F), collapse=", ")
}

# Create a csv file for manual curation
write.csv(summary_age_cols, 
          file = file.path(proj_dir, "curated_columns_map.csv"),
          row.names = FALSE)
```

Then we will create a dictionary of curated column keys with the list of their 
corresponding original columns as the value:
```{r}
# Put cols into a list
cols_to_curate <- hash()
for (col in unique(pot_col_map$curated_col)){
  col_name <- paste(col)
  cols_to_curate[[col_name]] <- unlist(str_split(pot_col_map$colnames.age_columns.[which(pot_col_map$curated_col==col_name)], ";"))
}
```

Now we can replace character values representing a lack of information with a 
unique character value ("8X8"), and merge these values into a single column with 
each distinct value separated by a semicolon.
```{r}
# Convert NA values to unique character value (8X8)
age_cols_cbio <- age_cols_cbio %>% replace(is.na(.), "8X8") %>% data.frame()

# Initialize dataframe
age_curated_cols <- data.frame(age_cols_cbio$curation_id)

# Loop through curations to merge relevant columns
for (curcol in keys(cols_to_curate)){
  # Merge all relevant rows
  for (i in 1:nrow(age_cols_cbio)){
    age_curated_cols[i,curcol] <- toupper(paste(age_cols_cbio[i,cols_to_curate[[curcol]]], collapse=";"))
  }
  print(curcol)
}
```

Next, we can remove the unique character representing NA values from the merged
column:
```{r}
for (i in 2:5){
  # Take out NA values
  age_curated_cols[,i] <- gsub("8X8;", "", age_curated_cols[,i])
  age_curated_cols[,i] <- gsub(";8X8", "", age_curated_cols[,i])
}
```

Then we can check if any merged column contains more than one age value per sample:
```{r}
# Sanity check for unique age values in each merged column
for (i in 1:ncol(age_curated_cols)){
  print(length(grep(";", age_curated_cols[,i])))
}
```

It appears that some samples contain two or more values in `age_at_procurement`.
We will need to standardize the unit metric applied by the original source
columns to address this. First, we will need to convert columns using "days" as 
their unit into "years":
```{r}
# Identify source columns with "days" unit
days_cols <- pot_col_map[which(pot_col_map$unit=="day"),]

# Convert columns from days to years
for (i in 1:nrow(days_cols)){
  age_cols_cbio[,days_cols$colnames.age_columns.[i]] <- data.frame(sapply(cbio[,days_cols$colnames.age_columns.[i]], function(x) as.integer(x)/365))
}
```

Next, we will need to convert columns using age groups as their unit
into a range of years by developing an age-group map:
```{r}
# Identify source columns with "group" unit
group_cols <- pot_col_map[which(pot_col_map$unit=="group"),]

unique_group_vals <- list()
for (i in group_cols$colnames.age_columns.){
  unique_group_vals <- unlist(append(unique_group_vals, unique(unlist(age_cols_cbio[,i]))))
}

# Make a csv file of the unique group values
write.csv(unique_group_vals, 
          file= file.path(proj_dir, "age_cbio_unique_vals.csv"), 
          row.names=F, col.names=F)
```


# Mapping

## Import Maps

To map the necessary age groups we will load the `cBioPortal_age_group_map`.
```{r import_maps, eval=FALSE}
# import location ontology map
mapped_terms <- read_sheet(ss, sheet = "cBioPortal_age_group_map")

# import location ontology map
mapped_terms <-read.csv(file = file.path(proj_dir, "cBioPortal_age_group_map.csv"), header=T)
```


# Curating Location Column

Using our adjusted values from columns originally in days and our range maps for
columns originally in age groups, we can first generate curated versions of our 
four main columns:
```{r}
# Remove columns with group units
cols_to_curate[["age_at_diagnosis"]] <- cols_to_curate[["age_at_diagnosis"]][-6]
cols_to_curate[["age_at_procurement"]] <- cols_to_curate[["age_at_procurement"]][-6]

# Convert NA values to unique character value (8X8)
age_cols_cbio <- age_cols_cbio %>% replace(is.na(.), "8X8") %>% data.frame()

# Loop through curations to merge relevant columns
for (curcol in keys(cols_to_curate)){
  # Merge all relevant rows
  for (i in 1:nrow(age_cols_cbio)){
    age_curated_cols[i,paste("curated", curcol, sep="_")] <- toupper(paste(age_cols_cbio[i,cols_to_curate[[curcol]]], collapse=";"))
  }
  print(curcol)
}

# Clean up extraneous NA values
for (i in 6:9){
  # Take out NA values
  age_curated_cols[,i] <- gsub("8X8;", "", age_curated_cols[,i])
  age_curated_cols[,i] <- gsub(";8X8", "", age_curated_cols[,i])
}

# Sanity Check and value selection
for (i in 6:ncol(age_curated_cols)){
  print(length(grep(";", age_curated_cols[,i])))
}
```

We can see that a number of samples still have multiple values in the 
`age_at_procurement`column, which we can standardize by opting to keep the higher
resolution value:
```{r}
# Investigate the multi-value cells
multival <- data.frame(age_curated_cols$curated_age_at_procurement[which(grepl(";", age_curated_cols$curated_age_at_procurement))])

# Prioritize "AGE_IN_DAYS" followed by "AGE" to standardize single values
for (r in 1:nrow(age_curated_cols)){
  if (grepl(";", age_curated_cols$curated_age_at_procurement[r])){
    if (age_cols_cbio$AGE_IN_DAYS[r]!="8X8"){
      age_curated_cols$curated_age_at_procurement[r] <- as.list(unlist(strsplit(as.character(age_curated_cols$curated_age_at_procurement[r]), ";")))[2]
    }else{
      age_curated_cols$curated_age_at_procurement[r] <- as.list(unlist(strsplit(as.character(age_curated_cols$curated_age_at_procurement[r]), ";")))[1]
    }
  }
}
```

Now we will implement the age group mapping to create minimum age and maximum
age columns for each curated column:
```{r}
# Create min and max columns for each curated column
for (colnam in colnames(age_curated_cols[,6:9])){
  age_curated_cols[,paste(colnam,"min", sep="_")] <- NA
  age_curated_cols[,paste(colnam,"max", sep="_")] <- NA
}

# Convert columns from age group to range of years
for (i in 1:nrow(group_cols)){
  for (y in 1:nrow(age_cols_cbio)){
    val <- mapped_terms$min[grep(paste("^",age_cols_cbio[y,group_cols$colnames.age_columns.[i]],"$",sep=""), mapped_terms$original_value, fixed=F)]
    age_curated_cols[y,paste("curated", group_cols$curated_col[i],"min", sep="_")] <- ifelse(identical(val, integer(0)), NA, val) 
    val <- mapped_terms$max[grep(paste("^",age_cols_cbio[y,group_cols$colnames.age_columns.[i]],"$",sep=""), mapped_terms$original_value, fixed=F)]
    age_curated_cols[y,paste("curated", group_cols$curated_col[i],"max", sep="_")] <- ifelse(identical(val, integer(0)), NA, val)
  }
}

# Fill in range values with higher resolution values and exact year values
for (colnam in colnames(age_curated_cols[,6:9])){
  for (r in 1:nrow(age_curated_cols)){
    if (age_curated_cols[r,colnam]!="8X8"){
      age_curated_cols[r,paste(colnam,"min", sep="_")] <- age_curated_cols[r,colnam]
      age_curated_cols[r,paste(colnam,"max", sep="_")] <- age_curated_cols[r,colnam]
    }
  }
}
```

Then we will add a column for the original age unit and the original source 
column:
```{r}
# Rebuild full cols_to_curate dictionary
cols_to_curate <- hash()
for (col in unique(pot_col_map$curated_col)){
  col_name <- paste(col)
  cols_to_curate[[col_name]] <- unlist(str_split(pot_col_map$colnames.age_columns.[which(pot_col_map$curated_col==col_name)], ";"))
}

# Create a function to return relevant columns given row and curated column name
rel_cols <- function(x, curcol){
  cols_to_curate[[curcol]][which(!is.na(cbio[x,cols_to_curate[[curcol]]]))]
}

# Create a function to format relevant columns
sources <- function(x, curcol){
  paste(rel_cols(x, curcol), collapse=";")
}

# Create a function to return formatted corresponding units for relevant columns
units <- function(x, curcol){
  paste(unique(pot_col_map$unit[which(pot_col_map$colnames.age_columns. %in% (rel_cols(x, curcol)))]), collapse=";")
}

# Loop through merged column names
for (curcol in keys(cols_to_curate)){
  # Create a column of relevant source columns for each merged column
  age_curated_cols[,paste("curated", curcol,"source", sep="_")] <- data.frame(sapply(1:nrow(age_curated_cols), function(x) ifelse(sources(x, curcol)=="", NA, sources(x, curcol))))
  # Create a column of relevant source column units for each merged column
  age_curated_cols[,paste("original", curcol,"unit", sep="_")] <- data.frame(sapply(1:nrow(age_curated_cols), function(x) ifelse(units(x, curcol)=="", NA, units(x, curcol))))
  # Print check-in
  print(curcol)
}
```

## Curated Table Creation

Next, we can clean up the dataframe by replacing the unique character 
representing NA values with "NA" and updating column names as needed:
```{r}
# Replace NA values from original columns with "NA"
age_curated_cols <- data.frame(lapply(age_curated_cols, 
                                          function(x) gsub("8X8", NA, x)))

# Rename the columns for accuracy & specificity
colnames(age_curated_cols)[1:5] <- c("curation_id", "original_age_at_death", "original_age_at_diagnosis", "original_age_at_metastasis", "original_age_at_procurement")

# Reorder the columns
curated_age <- age_curated_cols[,c(1,2,19,18,6,10,11,3,21,20,7,12,13,4,23,22,8,14,15,5,25,24,9,16,17)]

# Replace empty values from curated columns with "NA"
curated_age <- data.frame(lapply(curated_age, 
                                      function(x) gsub("^$", NA, x)))
```


## Export

Finally, we will export our completed table to GitHub.
```{r export_curated_table, eval=FALSE}
# export to GitHub
write.csv(curated_age, 
          file = file.path(proj_dir, "curated_age.csv"),
          row.names = FALSE)
```