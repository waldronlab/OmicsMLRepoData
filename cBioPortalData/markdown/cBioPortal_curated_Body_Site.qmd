---
title: "Harmonize body site information in cbio data"
author:
  - Sehyun Oh
  - Kai Gravel-Pucillo
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
    html:
        fontsize: 14pxs
        toc: true
        top-depth: 3
abstract: "Prepare U24 Supplement: AI/ML-ready"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                    warning = FALSE,
                    message = FALSE,
                    collapse = TRUE,
                    eval = TRUE)
```


# Overview

This .qmd file demonstrates a workflow for curating and harmonizing 
body site data with the cbioportal dataset.
This file curates information from 43 original columns to produce a curated 
column relating to the anatomical location of patients' disease/cancer.


# Setup

## Load Packages

```{r load}
suppressPackageStartupMessages({
 library(dplyr)
library(tidyverse)
library(stringr)
library(rvest)
library(rols)
library(vctrs)
library(hash)
})
```


## Setup for Curation

We will first add a `curation_id` consisting of study ID, patient ID, and sample ID (`studyId:patientId:sampleId`) to avoid confusion due to duplicated samples.
```{r curation_setup}
# Load cbio data
cbio <- readRDS("C:\\Users\\Owner\\Desktop\\CUNY Internship\\cBioPortal_all_clinicalData_combined_2023-05-18.rds")

# Add curation ID
cbio$curation_id <- paste(cbio$studyId, cbio$patientId, cbio$sampleId, sep = ":")

# Setup google sheets link to mapping table
url <- "https://docs.google.com/spreadsheets/d/1DKuoIt2xgSnkdkhYWffubmwrXLA7V7Z7pcqgb1TUXxo/edit#gid=0"

ss <- googledrive::as_id(url)

# Define a project directory
proj_dir <- "C:\\Users\\Owner\\Desktop\\CUNY Internship\\cbio\\Bodysite\\"
```


# Exploratory Data Analysis & Data Curation

## Identifying Relevant Columns & Completeness

Next, we will identify the columns containing values relating to the body site 
of the patients' cancer or disease.
Due to the large number of feature columns which contain a number of both broad
and very specific column types, we will first query column names for relevant 
terms and compile these results into a map of original columns and their
potential curated columns.
```{r}
# Create a list of potentially relevant columns based on search terms
bodysite_columns <- select(cbio, contains(c("disease", "cancer", "tumor", "type", "diagnosis", "site", "class", "loca"))) %>%
  select(-contains(c("radiation", "drug", "surgery", "treatment", "procedure")))

potential_columns <- data.frame(colnames(bodysite_columns))

# Iterate through these columns to create a dataframe of each column's unique values and completeness
for (col in 1:length(bodysite_columns)){
  potential_columns$unique_vals[col] <- paste(unlist(unique(bodysite_columns[,col]), use.names = F), collapse=" ")
  potential_columns$completeness[col] <- (nrow(bodysite_columns) - length(which(is.na(bodysite_columns[,col]))))/nrow(bodysite_columns)
}

# Remove rows where unique_vals is NA
potential_columns <- filter(potential_columns, unique_vals!="NA")

# Sort by completeness
potential_columns <- arrange(potential_columns, desc(completeness))

# Export to csv file to manually remove irrelevant columns
write.csv(potential_columns, 
          file = file.path(proj_dir, "potential_columns_map.csv"),
          row.names = FALSE)
```

After manually searching for character and boolean columns with titles pertaining 
to specific diseases or cancers and adding them to the map, as well as manually
removing and rearranging some columns which were irrelevant to this particular 
curation, we can then create a tibble dataframe and import the map of columns
to include in this curation:
```{r}
# Create tibble
cbio <- tibble(cbio)

# Load Potential columns map csv file
pot_col_map <- read.csv(file=file.path(proj_dir, "cBioPortal_curation_schema.csv"))

# Get list of all columns to combine into new body_site column
original_cols <- unlist(strsplit(pot_col_map$original_columns[8], ";"))

# Create a subset of cbio containing only relevant columns
bodysite_cols_cbio <- cbio[,c("curation_id", original_cols)]
```

Then we will evaluate the completeness and unique values of each of the relevant
columns, and export this dataframe to manually group columns into a smaller set
of curated columns:
```{r}
# Create a summary dataframe of the relevant columns
summary_bodysite_cols <- data.frame(colnames(bodysite_cols_cbio[,2:44]))

# Iterate through these columns to create a summary of each column's completeness
for (col in 1:nrow(summary_bodysite_cols)){
  summary_bodysite_cols$completeness[col] <- (nrow(bodysite_cols_cbio) - length(which(is.na(bodysite_cols_cbio[,col+1]))))/nrow(bodysite_cols_cbio)
  summary_bodysite_cols$num_na_vals[col] <- length(which(is.na(bodysite_cols_cbio[,col+1])))
  summary_bodysite_cols$unique[col] <- paste(unlist(unique(bodysite_cols_cbio[,col+1]), use.names=F), collapse=", ")
}

# Create a csv file for manual curation
write.csv(summary_bodysite_cols, 
          file = file.path(proj_dir, "curated_columns_map.csv"),
          row.names = FALSE)
```

Creating a table of each column's unique values and completeness reveals that
across all data entries there is a minimum of approximately 1.1% completeness 
prior to the removal of non-NA values indicating "no response" or "unknown".
Before we condense these values into a single merged column, we will need to 
convert some columns from binary values into descriptive values:
```{r}
# Convert Yes/No and T/F columns to descriptive values
# Create a dataframe of the relevant columns
binary_cols <- c("DIAGNOSIS_CANCER_BONE", "DIAGNOSIS_CANCER_LOC_ASCITES",
                 "DIAGNOSIS_CANCER_LOC_AXILLARY_LN", "DIAGNOSIS_CANCER_LOC_BRAIN",
                 "DIAGNOSIS_CANCER_LOC_BREAST", "DIAGNOSIS_CANCER_LOC_CHEST_WALL",
                 "DIAGNOSIS_CANCER_LOC_LIVER", "DIAGNOSIS_CANCER_LOC_LUNG",
                 "DIAGNOSIS_CANCER_LOC_OTHER_LN", "DIAGNOSIS_CANCER_LOC_OVARY",
                 "DIAGNOSIS_CANCER_LOC_PLEURAL_EFFUSION", "LOCALIZED_TUMOR",
                 "DIAGNOSIS_CANCER_LOC_SKIN", "DISEASE_MULTIFOCAL_INDICATOR", 
                 "MULTIPLE_TUMOR_LOCATIONS")
binary_value_cols <- select(bodysite_cols_cbio, all_of(c("curation_id", binary_cols)))

# Create a summary dataframe of the relevant columns
summary_binary_val_cols <- data.frame(colnames(binary_value_cols))
# Iterate through columns to get unique vals
for (col in 1:nrow(summary_binary_val_cols)){
  summary_binary_val_cols$unique_vals[col] <- unique(binary_value_cols[,col])
}

binary_value_cols_og <- binary_value_cols

# Replace logical values with character values
binary_value_cols <- data.frame(lapply(binary_value_cols, function(x) gsub(TRUE, "TRUE", x)))
binary_value_cols <- data.frame(lapply(binary_value_cols, function(x) gsub(FALSE, "FALSE", x)))

# Update binary columns with descriptive values
present_vals <- c("YES", "Yes", "y", "TRUE", "Positive")
for(col in colnames(binary_value_cols[,2:16])){
  for (val in 1:nrow(binary_value_cols)){
    if (binary_value_cols[val,col] %in% present_vals){
      binary_value_cols[val,col] <- col
    }else{
      binary_value_cols[val,col] <- NA
    }
  }
}

# Remove underscores
binary_value_cols <- data.frame(lapply(binary_value_cols, function(x) gsub("_", " ", x)))

# Replace values in bodysite_cols_cbio
bodysite_cols_cbio[,binary_cols] <- binary_value_cols[,2:16]
```

Additionally, two values ("Head" and "Body") have been identified which represent
different anatomical locations depending on the column from which the term is 
originating due to different uses of the term in different studies. To prevent
inaccurate mapping of these terms, we can change the original value in certain
columns to be unique:
```{r}
# Distinguish different uses of "Head" in LOCATION column
bodysite_cols_cbio$LOCATION <- sapply(bodysite_cols_cbio$LOCATION, function(x) gsub("^Head$", "HeadRegular", x))

bodysite_cols_cbio$LOCATION <- cbio$LOCATION
bodysite_cols_cbio$TUMOR_SITE <- cbio$TUMOR_SITE

# Distinguish different uses of "Body" based on origin study in LOCATION column
bodysite_cols_cbio$LOCATION[which(cbio$studyId=="egc_tmucih_2015")] <- sapply(bodysite_cols_cbio$LOCATION[which(cbio$studyId=="egc_tmucih_2015")], function(x) gsub("^Body$", "BodyStomach", x))

# Distinguish different uses of "Body" based on origin study in TUMOR_SITE column
bodysite_cols_cbio$TUMOR_SITE[which(cbio$studyId=="stad_oncosg_2018")] <- sapply(bodysite_cols_cbio$TUMOR_SITE[which(cbio$studyId=="stad_oncosg_2018")], function(x) gsub("^Body$", "BodyStomach", x))
```

Now that all columns include descriptive values, we can replace character values
representing a lack of information with a unique character value ("8X8"), and 
merge these values into a single column with each distinct value separated by a 
special 3-character delimiter ("<;>"). This delimiter was implemented so as to
preserve curated ontology terms containing semicolons, which are the main 
delimiter utilized in the broader curation.
```{r}
# Convert NA values to unique character value (8X8)
bodysite_cols_cbio <- bodysite_cols_cbio %>% replace(is.na(.), "8X8") %>% data.frame()

# Merge all relevant rows
for (i in 1:nrow(bodysite_cols_cbio)){
  bodysite_cols_cbio$merged[i] <- toupper(paste(bodysite_cols_cbio[i,2:44], collapse="<;>"))
}
```

Next, we can remove the unique character representing NA values from the merged
column. Additionally we can remove the pipe delimiter from all values to 
prevent interpretation of the pipe as a regex character during queries:
```{r}
# Take out NA values
bodysite_cols_cbio$merged <- gsub("8X8<;>", "", bodysite_cols_cbio$merged)
bodysite_cols_cbio$merged <- gsub("<;>8X8", "", bodysite_cols_cbio$merged)

# Remove pipes and parentheses
bodysite_cols_cbio <- data.frame(lapply(bodysite_cols_cbio, function(x) gsub("\\|", "", x)))
bodysite_cols_cbio <- data.frame(lapply(bodysite_cols_cbio, function(x) gsub("\\(", "", x)))
bodysite_cols_cbio <- data.frame(lapply(bodysite_cols_cbio, function(x) gsub("\\)", "", x)))

```

Then we can create a list of all unique values included in the merged column,
and export these values to a csv file to manually develop an ontology map:
```{r}
# Count the number of unique values in the merged column (805)
merged_vals <- list()
for(r in 1:nrow(bodysite_cols_cbio)){
  merged_vals <- append(merged_vals, str_split(bodysite_cols_cbio$merged[r], "<;>"))
}
unique_merged_vals <- unique(unlist(merged_vals))

# Make a csv file of the unique values in the merged column
write.csv(unique_merged_vals, 
          file= file.path(proj_dir, "body_site_cbio_unique_vals.csv"), 
          row.names=F, col.names=F)
```


# Mapping

## Import Maps

To access the necessary body site ontology terms we will load the 
`body_site_ontology_map`.
```{r import_maps, eval=FALSE}
# import body_site ontology map
mapped_terms <- read_sheet(ss, sheet = "cBioPortal_body_site_map")

# import body_site ontology map
mapped_terms <-read.csv(file = file.path(proj_dir, "cBioPortal_body_site_map.csv"), header=T)
```


# Curating Body_site Columns

Now we can map the values in the merged columns to their corresponding ontology
terms and propagate these values into the curated columns: 
```{r}
# Make a function to remove excess semicolons
rmv_xtra_semis <- function(x){
  x <- ifelse(startsWith(x, "<;>"), sub("^<;>", "", x), x)
  return(ifelse(endsWith(x, "<;>"), sub("<;>$", "", x), x))
}

# Make function to format the list output as a single cell value
format_list <- function(vals_list, delim){
  rmv_xtra_semis(paste(as.list(unique(vals_list)), collapse= delim))
}

# Iterate through merged column values
for (x in 1:length(bodysite_cols_cbio$merged)){
  # Create a list of terms in the value
  original_terms <- as.list(unlist(strsplit(bodysite_cols_cbio$merged[x], "<;>")))
  new_terms <- list()
  new_term_ids <- list()
  # Search for replacement terms in the ontology map
  new_terms <- lapply(original_terms, function(y) format_list(list_drop_empty(as.list(mapped_terms$curated_ontology[grep(paste("^",y,"$",sep=""), mapped_terms$original_value, fixed=F)])), "<;>"))
  new_term_ids <- lapply(original_terms, function(y) format_list(list_drop_empty(as.list(mapped_terms$curated_ontology_term_id[grep(paste("^",y,"$",sep=""), mapped_terms$original_value, fixed=F)])), "<;>"))
  new_terms <- format_list(list_drop_empty(new_terms), "<;>")
  new_term_ids <- format_list(list_drop_empty(new_term_ids), "<;>")
  # Concatenate new lists on ";" delimiter to create curated value
  bodysite_cols_cbio$curated_body_site[x] <- format_list(as.list(unlist(strsplit(new_terms, "<;>"))), "<;>")
  bodysite_cols_cbio$curated_body_site_ontology_term_id[x] <- format_list(as.list(unlist(strsplit(new_term_ids, "<;>"))), "<;>")
  if(x %% 10000==0){print(x)}
}
```


## Curated Table Creation

Next, we can clean up the dataframe by replacing the unique character 
representing NA values with "NA" and updating column names as needed:
```{r}
# Replace NA values from original columns with "NA"
bodysite_cols_cbio <- data.frame(lapply(bodysite_cols_cbio, 
                                          function(x) gsub("8X8", NA, x)))

# Create a column of relevant source columns
for (i in 1:nrow(bodysite_cols_cbio)){
  bodysite_cols_cbio$curated_body_site_source[i] <- paste(colnames(bodysite_cols_cbio[,2:44][which(!is.na(bodysite_cols_cbio[i,2:44]))]), collapse="<;>")
}

# Create a curated dataframe
curated_bodysite <- bodysite_cols_cbio[,c(1, 45:48)]

# Rename the columns for accuracy & specificity
colnames(curated_bodysite)[1:2] <- c("curation_id", "original_body_site")

# Replace empty values from curated columns with "NA"
curated_bodysite <- data.frame(lapply(curated_bodysite, 
                                      function(x) gsub("^$", NA, x)))
```


## Export

Finally, we will export our completed table to GitHub.
```{r export_curated_table, eval=FALSE}
# export to GitHub
write.csv(curated_bodysite, file = file.path(proj_dir, "curated_body_site.csv"), 
          row.names=F)
```