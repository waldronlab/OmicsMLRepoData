---
title: "Update Curated Data without Re-running Curation File"
author:
  - Sehyun Oh
  - Kai Gravel-Pucillo
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
    html:
        fontsize: 14pxs
        toc: true
        top-depth: 3
abstract: "Prepare U24 Supplement: AI/ML-ready"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                    warning = FALSE,
                    message = FALSE,
                    collapse = TRUE,
                    eval = TRUE)
```

# Overview

This .qmd file demonstrates a workflow for updating any curated datafile by 
implementing a new or updated mapping schema without needing to rerun the full 
curation workflow.

# Setup
## Load Packages

```{r load}
suppressPackageStartupMessages({
  library(curatedMetagenomicData)
  library(tidyverse)
  library(googlesheets4)
  library(rols)
  library(dplyr)
  library(hash)
  library(vctrs)
  library(rvest)
  library(stringr)
  library(diffdf)
})
```

## Set Parameters

First we will set the working directory, set the file name of the new map, set the
file name of the curated data to be updated, select the column to update, and set
the delimiter of the curated data column.
```{r}
# Define a project directory
proj_dir <- "C:\\Users\\Owner\\Desktop\\CUNY Internship\\cbio\\Bodysite\\"

# Define updated map name
map <- "cBioPortal_bodysite_map.csv"

# Define curated data
curated_data <- "curated_bodysite.csv"

# Define column name
col_name <- "bodysite"

# Define delimiter for curated data file
delimiter <- "<;>"
```

## Load Files

Next we will load the files using our preset parameters:
```{r}
# Read in updated map
new_map <-read.csv(file = file.path(proj_dir, map), header=T)

# Read in original curated data
new_curated_df <- og_curated_df <-read.csv(file = file.path(proj_dir, curated_data), header=T)
```

# Update Curated Data File

Then we will update the curated data file by using the new map to re-map the 
selected column:
```{r}
# Create original column and curated column variables
og_col <- paste("original", col_name, sep="_")
new_col <- paste("curated", col_name, sep="_")

# Make a function to remove excess semicolons
rmv_xtra_semis <- function(x, delimiter){
    x <- ifelse(startsWith(x, delimiter), sub(paste("^", delimiter, sep=""), "", x), x)
    return(ifelse(endsWith(x, delimiter), sub(paste(delimiter, "$", sep=""), "", x), x))
}

# Make function to format the list output as a single cell value
format_list <- function(vals_list, delim){
    rmv_xtra_semis(paste(as.list(unique(vals_list)), collapse= delim), delimiter)
}

# Iterate through merged column values
for (x in 1:nrow(new_curated_df)){
    # Create a list of terms in the value
    original_terms <- unlist(strsplit(new_curated_df[x,og_col], delimiter))
    new_terms <- list()
    new_term_ids <- list()
    # Search for replacement terms in the ontology map
    new_terms <- lapply(original_terms, function(y) format_list(list_drop_empty(as.list(new_map$curated_ontology[grep(paste("^",y,"$",sep=""), new_map$original_value, fixed=F)])), delimiter))
    new_term_ids <- lapply(original_terms, function(y) format_list(list_drop_empty(as.list(new_map$curated_ontology_term_id[grep(paste("^",y,"$",sep=""), new_map$original_value, fixed=F)])), delimiter))
    new_terms <- format_list(list_drop_empty(new_terms), delimiter)
    new_term_ids <- format_list(list_drop_empty(new_term_ids), delimiter)
    # Concatenate new lists on delimiter to create curated value
    new_curated_df[x,new_col] <- format_list(as.list(unlist(strsplit(new_terms, delimiter))), delimiter)
    new_curated_df[x,paste(new_col, "ontology_term_id", sep="_")] <- format_list(as.list(unlist(strsplit(new_term_ids, delimiter))), delimiter)
    if(x %% 10000==0){print(x)}
}

# Replace empty values from curated columns with "NA"
new_curated_df <- data.frame(lapply(new_curated_df, 
                                      function(x) gsub("^$", NA, x)))
```

# Validation

Next we can check that the updated dataframe only has the changes we would 
expect from our updated map.
```{r}
# Check the differences between the original and re-mapped dataframes
diffdf(new_curated_df, og_curated_df)
```

# Export
Finally, we will export our updated curated data file and add the date it was 
updated to the file name.
```{r export_curated_table, eval=FALSE}
# Export updated curated data file
write.csv(new_curated_df, 
          file = file.path(proj_dir, 
                           paste(unlist(strsplit(curated_data, "\\."))[1], "_", 
                                           toupper(format(Sys.time(), "%d%b%Y")), 
                                           ".csv", sep="")),
          row.names = FALSE)
```